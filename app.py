import gradio as gr
import torch
import soundfile as sf
import os
import datetime
import re
import shutil
import numpy as np
from qwen_tts import Qwen3TTSModel

# ================= é…ç½®åŒºåŸŸ =================
# æ³¨æ„ï¼šGitHub ä¸Šä¸ä¼ å¤§æ¨¡å‹ï¼Œè®©ç”¨æˆ·è‡ªå·±æŠŠæ¨¡å‹è§£å‹åˆ°è¿™ä¸ªæ–‡ä»¶å¤¹
MODEL_PATH = "Qwen3-Base"
VOICE_DIR = "my_voices"
OUTPUT_DIR = "recordings"

# è‡ªåŠ¨åˆ›å»ºç›®å½•
for d in [VOICE_DIR, OUTPUT_DIR]:
    if not os.path.exists(d):
        os.makedirs(d)

print("="*60)
print("ğŸš€ Qwen3-Voice-Studio (8GB æ˜¾å­˜ä¼˜åŒ–ç‰ˆ) å¯åŠ¨ä¸­...")
print("="*60)

# ================= æ ¸å¿ƒå¼•æ“ (Engine) =================
try:
    print(f"â³ æ­£åœ¨åŠ è½½æ¨¡å‹ (è·¯å¾„ï¼š{os.path.abspath(MODEL_PATH)})...")

    # æ˜¾å­˜æ¸…ç†
    if torch.cuda.is_available():
        torch.cuda.empty_cache()

    # æ ¸å¿ƒä¼˜åŒ–ï¼šä½¿ç”¨ bfloat16 å’Œ flash-attention/sdpa èŠ‚çœæ˜¾å­˜
    model = Qwen3TTSModel.from_pretrained(
        MODEL_PATH,
        device_map="cuda:0",
        dtype=torch.bfloat16,
        attn_implementation="sdpa"
    )
    print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")
except Exception as e:
    print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼š{e}")
    print("ğŸ’¡ è¯·ç¡®ä¿ä½ å·²ç»ä¸‹è½½äº† Qwen3-TTS æ¨¡å‹å¹¶æ”¾åœ¨ 'Qwen3-Base' æ–‡ä»¶å¤¹ä¸­ã€‚")
    model = None

# ================= ä¸šåŠ¡é€»è¾‘ (Logic) =================

def get_voice_list():
    if not os.path.exists(VOICE_DIR): return []
    return [f for f in os.listdir(VOICE_DIR) if f.endswith(('.wav', '.mp3'))]

def split_text(text):
    """é•¿æ–‡æœ¬åˆ‡åˆ†ç®—æ³•"""
    sentences = re.split(r'([ï¼Œã€‚ï¼ï¼Ÿï¼›,.!?;])', text)
    parts = []
    for i in range(0, len(sentences)-1, 2):
        parts.append(sentences[i] + sentences[i+1])
    if len(sentences) % 2 == 1:
        parts.append(sentences[-1])
    return [p.strip() for p in parts if p.strip()]

def clone_voice(audio, text, lang):
    if model is None: return None, "âŒ é”™è¯¯ï¼šæ¨¡å‹æœªåŠ è½½"
    if not audio: return None, "âš ï¸ è¯·å…ˆä¸Šä¼ å£°éŸ³"

    try:
        torch.cuda.empty_cache()
        wavs, sr = model.generate_voice_clone(
            text=text,
            ref_audio=audio,
            x_vector_only_mode=True,
            language=lang
        )
        out_path = os.path.join(OUTPUT_DIR, "temp_preview.wav")
        sf.write(out_path, wavs[0], sr)
        return out_path, "âœ… åˆæˆæˆåŠŸ"
    except Exception as e:
        return None, f"âŒ æŠ¥é”™ï¼š{str(e)}"

def save_voice(audio, name):
    if not audio or not name: return gr.update(), "âŒ ç¼ºå°‘éŸ³é¢‘æˆ–åç§°"
    safe_name = "".join([c for c in name if c.isalnum() or c in (' ', '_', '-')]).strip()
    save_path = os.path.join(VOICE_DIR, f"{safe_name}.wav")
    shutil.copy(audio, save_path)
    return gr.update(choices=get_voice_list(), value=f"{safe_name}.wav"), f"å·²ä¿å­˜ï¼š{safe_name}"

def tts_long(text, voice, lang):
    if model is None: return None, "âŒ æ¨¡å‹æœªåŠ è½½"
    if not voice: return None, "âš ï¸ è¯·é€‰æ‹©éŸ³è‰²"

    try:
        voice_path = os.path.join(VOICE_DIR, voice)
        parts = split_text(text)
        all_audio = []
        sr = 24000

        for part in parts:
            torch.cuda.empty_cache() # é˜²æ­¢çˆ†æ˜¾å­˜
            wavs, sr = model.generate_voice_clone(
                text=part, ref_audio=voice_path,
                x_vector_only_mode=True, language=lang
            )
            all_audio.append(wavs[0])

        final_wav = np.concatenate(all_audio)
        out_name = f"tts_{datetime.datetime.now().strftime('%H%M%S')}.wav"
        out_path = os.path.join(OUTPUT_DIR, out_name)
        sf.write(out_path, final_wav, sr)
        return out_path, f"âœ… é•¿æ–‡æœ¬åˆæˆå®Œæ¯•ï¼š{out_name}"
    except Exception as e:
        return None, f"âŒ åˆæˆå‡ºé”™ï¼š{str(e)}"

# ================= ç•Œé¢ (UI) =================
with gr.Blocks(title="Qwen3 Voice Studio", theme=gr.themes.Soft()) as demo:
    gr.Markdown("## ğŸ™ï¸ Qwen3-Voice-Studio (æœ¬åœ°ç‰ˆ)")
    gr.Markdown("åŸºäº Qwen3-TTS | æ”¯æŒ 8GB æ˜¾å­˜ | é•¿æ–‡æœ¬åˆæˆ | éŸ³è‰²å…‹éš†")

    with gr.Tab("âœ¨ éŸ³è‰²å…‹éš†"):
        with gr.Row():
            with gr.Column():
                inp_audio = gr.Audio(type="filepath", label="1. ä¸Šä¼ å¹²å£° (3-10s)")
                inp_text = gr.Textbox(value="ä½ å¥½ï¼Œè¿™æ˜¯æˆ‘çš„å£°éŸ³å…‹éš†æµ‹è¯•ã€‚", label="2. æµ‹è¯•æ–‡æœ¬")
                btn_test = gr.Button("ğŸš€ æµ‹è¯•åˆæˆ", variant="primary")
            with gr.Column():
                out_audio = gr.Audio(label="3. è¯•å¬ç»“æœ")
                inp_name = gr.Textbox(placeholder="ä¾‹å¦‚ï¼šè€ç‹", label="4. éŸ³è‰²å‘½å")
                btn_save = gr.Button("ğŸ’¾ ä¿å­˜åˆ°éŸ³è‰²åº“")
                log_1 = gr.Textbox(label="æ—¥å¿—")

    with gr.Tab("ğŸ“– é•¿æ–‡æœ¬åˆæˆ"):
        with gr.Row():
            with gr.Column():
                drop_voice = gr.Dropdown(choices=get_voice_list(), label="é€‰æ‹©éŸ³è‰²")
                drop_lang = gr.Dropdown(choices=["Chinese", "English"], value="Chinese", label="è¯­è¨€")
                txt_long = gr.Textbox(lines=6, label="è¾“å…¥é•¿æ–‡æœ¬")
                btn_run = gr.Button("å¼€å§‹åˆæˆ", variant="primary")
            with gr.Column():
                out_final = gr.Audio(label="åˆæˆç»“æœ")
                log_2 = gr.Textbox(label="æ—¥å¿—")

    btn_test.click(clone_voice, [inp_audio, inp_text, drop_lang], [out_audio, log_1])
    btn_save.click(save_voice, [inp_audio, inp_name], [drop_voice, log_1])
    btn_run.click(tts_long, [txt_long, drop_voice, drop_lang], [out_final, log_2])

if __name__ == "__main__":
    demo.launch(inbrowser=True)
